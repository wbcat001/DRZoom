{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a928ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hdbscan\n",
    "import umap\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.datasets import make_blobs\n",
    "from typing import List, Tuple\n",
    "# mnist\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd68ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\acero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- 1. データ生成とHDBSCANの実行 ---\n",
    "\n",
    "# 階層的な構造を持つダミーデータを生成\n",
    "X, y = make_blobs(n_samples=2000, centers=8, cluster_std=1.0, random_state=42)\n",
    "# さらにクラスタを近づけて複雑な階層構造を作る\n",
    "X[:500, :] += 5 \n",
    "X[500:1000, :] -= 5\n",
    "\n",
    "# HDBSCANの実行\n",
    "hdb = hdbscan.HDBSCAN(min_cluster_size=20, min_samples=5, prediction_data=True).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c00355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\acero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# UMAPによる初期の2次元埋め込み (全データ対象)\n",
    "mapper = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42).fit(X)\n",
    "initial_embedding = mapper.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ea50b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda range: 0.270260757467077 to 4.328284387358554\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# HDBSCANのデンドログラムからシミュレーション用のλ値を定義\n",
    "# λが小さいほど粗いクラスタリング (Overview)\n",
    "condensed_tree = hdb.condensed_tree_.to_pandas()\n",
    "min_lambda = condensed_tree['lambda_val'].min()\n",
    "max_lambda = condensed_tree['lambda_val'].max()\n",
    "print(f\"Lambda range: {min_lambda} to {max_lambda}\")\n",
    "\n",
    "# 3つのズームレベルに対応するλ値を設定 (Overview, Mid, Details)\n",
    "lambda_levels = {\n",
    "    \"Level 1: Overview (粗い)\": min_lambda + (max_lambda - min_lambda) * 0.1,\n",
    "    \"Level 2: Mid-Zoom (中間)\": min_lambda + (max_lambda - min_lambda) * 0.4,\n",
    "    \"Level 3: Details (詳細)\": min_lambda + (max_lambda - min_lambda) * 0.8\n",
    "}\n",
    "\n",
    "df_full = pd.DataFrame(initial_embedding, columns=['x', 'y'])\n",
    "df_full['index'] = df_full.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92da880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. 分析ロジックとプロット関数の定義 ---\n",
    "\n",
    "def get_snapshot_data(X: np.ndarray, current_lambda: float, level_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    指定されたlambda値でクラスタリングを行い、代表点を抽出し、UMAPを再計算する (シミュレーション)。\n",
    "    \n",
    "    Args:\n",
    "        X: 高次元データ\n",
    "        current_lambda: HDBSCANのカットレベル (lambda値)\n",
    "        level_name: プロット用のレベル名\n",
    "        \n",
    "    Returns:\n",
    "        プロット用のDataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 指定lambda値でのクラスタリングを取得\n",
    "    # hdbscan.label.hdbscan_tree_to_labelsは内部関数であり、ここではシミュレーションとして\n",
    "    # 簡略化されたラベル抽出ロジックを使用\n",
    "    labels, _ = hdbscan.label.hdbscan_tree_to_labels(\n",
    "        hdb.condensed_tree_, X.shape[0], lambda_val=current_lambda\n",
    "    )\n",
    "    \n",
    "    # 2. 代表点（コア点）の抽出 (シミュレーション)\n",
    "    representative_indices = []\n",
    "    unique_clusters = np.unique(labels[labels != -1])\n",
    "    \n",
    "    for cid in unique_clusters:\n",
    "        member_indices = np.where(labels == cid)[0]\n",
    "        if len(member_indices) > 0:\n",
    "            # 実際の代表点ロジック: Core Distance最小の点を抽出\n",
    "            core_distances = hdb.core_distances_[member_indices]\n",
    "            core_point_index_in_member = np.argmin(core_distances)\n",
    "            representative_indices.append(member_indices[core_point_index_in_member])\n",
    "\n",
    "    if not representative_indices:\n",
    "        # 代表点がない場合、全点を使用 (フォールバック)\n",
    "        representative_indices = np.arange(X.shape[0])\n",
    "    \n",
    "    # 3. 代表点のみに限定したUMAPの再計算 (または以前の結果からの初期配置)\n",
    "    # ここでは、**代表点のみ**を使ってUMAPを再計算する**「意味的ズーム」**をシミュレーション\n",
    "    X_rep = X[representative_indices]\n",
    "    \n",
    "    # UMAPの初期配置を前の埋め込み結果から継承する処理は複雑なため省略し、ここでは新規計算\n",
    "    mapper_rep = umap.UMAP(n_neighbors=5, min_dist=0.1, random_state=42).fit(X_rep)\n",
    "    embedding_rep = mapper_rep.embedding_\n",
    "    \n",
    "    # 4. DataFrameの作成\n",
    "    df_rep = pd.DataFrame(embedding_rep, columns=['x', 'y'])\n",
    "    df_rep['cluster'] = labels[representative_indices]\n",
    "    df_rep['is_rep'] = True\n",
    "    df_rep['level'] = level_name\n",
    "    \n",
    "    return df_rep\n",
    "\n",
    "def plot_snapshots(df_list: List[pd.DataFrame]):\n",
    "    \"\"\"複数のスナップショットをPlotlyで描画\"\"\"\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # 1. 全てのデータを一つのDataFrameに結合\n",
    "    df_combined = pd.concat(df_list)\n",
    "    \n",
    "    # 2. Plotlyのサブプロット設定（1行3列）\n",
    "    for i, (level, df) in enumerate(zip(lambda_levels.keys(), df_list)):\n",
    "        row = 1\n",
    "        col = i + 1\n",
    "\n",
    "        # 3. 散布図の追加\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df['x'],\n",
    "                y=df['y'],\n",
    "                mode='markers',\n",
    "                name=level,\n",
    "                marker=dict(\n",
    "                    size=10, \n",
    "                    # クラスタIDで色付け\n",
    "                    color=df['cluster'],\n",
    "                    colorscale='Turbo', \n",
    "                    showscale=False,\n",
    "                    line=dict(width=1, color='DarkSlateGrey') \n",
    "                ),\n",
    "                hovertemplate=f\"Cluster: %{{customdata[0]}}<br>Index: %{{customdata[1]}}<extra>{level}</extra>\",\n",
    "                customdata=np.stack((df['cluster'], df['index'] if 'index' in df.columns else np.arange(len(df))), axis=-1),\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "            # タイトルは後のレイアウトで設定\n",
    "        )\n",
    "\n",
    "        # 4. レイアウトの調整\n",
    "        fig.update_xaxes(title_text=\"UMAP Dimension 1\", row=row, col=col, showgrid=False, zeroline=False)\n",
    "        fig.update_yaxes(title_text=\"UMAP Dimension 2\", row=row, col=col, showgrid=False, zeroline=False)\n",
    "\n",
    "    # 5. グローバルレイアウト\n",
    "    fig.update_layout(\n",
    "        title_text=\"階層的ドリルダウン分析のスナップショット\",\n",
    "        height=500,\n",
    "        showlegend=False,\n",
    "        # サブプロットのレイアウトを定義 (1行3列)\n",
    "        grid={'rows': 1, 'columns': 3, 'pattern': 'independent'}, \n",
    "    )\n",
    "    \n",
    "    # 各プロットにタイトルを適用\n",
    "    annotations = []\n",
    "    for i, level in enumerate(lambda_levels.keys()):\n",
    "        annotations.append(dict(\n",
    "            xref='x domain', yref='y domain',\n",
    "            x=0.5 + i, y=1.05,\n",
    "            text=f\"**{level}** ({len(df_list[i])} 代表点)\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=14),\n",
    "            xanchor='center',\n",
    "            yanchor='bottom'\n",
    "        ))\n",
    "    fig.update_layout(annotations=annotations)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da78f8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hdbscan._hdbscan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhdbscan\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_hdbscan\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhdbscan_internal\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hdbscan._hdbscan'"
     ]
    }
   ],
   "source": [
    "import hdbscan._hdbscan as hdbscan_internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ce8fe4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'hdbscan' has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m snapshot_data_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m level_name, lambda_val \u001b[38;5;129;01min\u001b[39;00m lambda_levels\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 6\u001b[0m     df_snapshot \u001b[38;5;241m=\u001b[39m \u001b[43mget_snapshot_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     df_snapshot[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_snapshot\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;66;03m# インデックスを一旦保持\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     snapshot_data_list\u001b[38;5;241m.\u001b[39mappend(df_snapshot)\n",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m, in \u001b[0;36mget_snapshot_data\u001b[1;34m(X, current_lambda, level_name)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m指定されたlambda値でクラスタリングを行い、代表点を抽出し、UMAPを再計算する (シミュレーション)。\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    プロット用のDataFrame\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 1. 指定lambda値でのクラスタリングを取得\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# hdbscan.label.hdbscan_tree_to_labelsは内部関数であり、ここではシミュレーションとして\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 簡略化されたラベル抽出ロジックを使用\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m labels, _ \u001b[38;5;241m=\u001b[39m \u001b[43mhdbscan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[38;5;241m.\u001b[39mhdbscan_tree_to_labels(\n\u001b[0;32m     20\u001b[0m     hdb\u001b[38;5;241m.\u001b[39mcondensed_tree_, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], lambda_val\u001b[38;5;241m=\u001b[39mcurrent_lambda\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 2. 代表点（コア点）の抽出 (シミュレーション)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m representative_indices \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'hdbscan' has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- 3. スナップショットの生成 ---\n",
    "snapshot_data_list = []\n",
    "for level_name, lambda_val in lambda_levels.items():\n",
    "    df_snapshot = get_snapshot_data(X, lambda_val, level_name)\n",
    "    df_snapshot['index'] = df_snapshot.index # インデックスを一旦保持\n",
    "    snapshot_data_list.append(df_snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 4. 結果の描画 ---\n",
    "# Plotlyのサブプロット機能を使って3つの図を並列表示\n",
    "\n",
    "# サブプロットキャンバスの準備\n",
    "fig = make_subplots(rows=1, cols=3, \n",
    "                    subplot_titles=list(lambda_levels.keys()),\n",
    "                    horizontal_spacing=0.05)\n",
    "\n",
    "# 各レベルのデータをプロットに追加\n",
    "for i, df in enumerate(snapshot_data_list):\n",
    "    level_name = list(lambda_levels.keys())[i]\n",
    "    \n",
    "    # Scatter Trace の設定\n",
    "    trace = go.Scatter(\n",
    "        x=df['x'],\n",
    "        y=df['y'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10, \n",
    "            # クラスタIDで色付け\n",
    "            color=df['cluster'],\n",
    "            colorscale='Turbo',\n",
    "            colorbar=dict(title='Cluster ID', titleside='right') if i == 2 else None, # 最後のプロットのみカラーバー表示\n",
    "            showscale=False,\n",
    "            line=dict(width=1, color='DarkSlateGrey')\n",
    "        ),\n",
    "        name=level_name,\n",
    "        hovertemplate=f\"Cluster: %{{customdata[0]}}<br>Point: %{{customdata[1]}}<extra>{level_name}</extra>\",\n",
    "        customdata=np.stack((df['cluster'], df['index']), axis=-1)\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(trace, row=1, col=i + 1)\n",
    "    \n",
    "    # サブプロットタイトルを更新 (Plotly Subplotsの都合上、後で更新)\n",
    "    fig.layout.annotations[i].update(text=f\"**{level_name}** ({len(df)} 代表点)\")\n",
    "\n",
    "# グローバルレイアウトの調整\n",
    "fig.update_layout(\n",
    "    title_text=\"HDBSCAN階層を利用した意味的ズーム分析スナップショット\",\n",
    "    height=500,\n",
    "    width=1200,\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showgrid=False, zeroline=False)\n",
    "fig.update_yaxes(showgrid=False, zeroline=False)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
