{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d4c22a",
   "metadata": {},
   "source": [
    "## 1. 必要なライブラリと関数のインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce255d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import inv, det\n",
    "import warnings\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from typing import Dict, List\n",
    "import pickle\n",
    "\n",
    "print(\"ライブラリをインポートしました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc176e",
   "metadata": {},
   "source": [
    "## 2. 統計量計算関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_single_gaussian_params(X_data: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    単一の高次元データセットから、多変量正規分布の平均ベクトルと共分散行列を推定する。\n",
    "    サンプル数が次元数より少ない場合、Ledoit-Wolf収縮法を用いて共分散行列を頑健に推定する。\n",
    "\n",
    "    Args:\n",
    "        X_data (np.ndarray): 単一のクラスタ（またはデータセット）に属するデータ (N, D)。\n",
    "\n",
    "    Returns:\n",
    "        Dict: {'mu': 平均ベクトル, 'Sigma': 共分散行列}\n",
    "    \"\"\"\n",
    "    N, D = X_data.shape # サンプル数 N, 次元数 D\n",
    "\n",
    "    if N == 0:\n",
    "        raise ValueError(\"Input data array must not be empty.\")\n",
    "    \n",
    "    # 1. 平均ベクトル (mu) の推定\n",
    "    mu = np.mean(X_data, axis=0)\n",
    "\n",
    "    # 2. 共分散行列 (Sigma) の推定\n",
    "    if N == 1:\n",
    "        # サンプル数が1の場合、共分散はゼロ\n",
    "        warnings.warn(\"N=1. Covariance matrix is set to zero (plus regularization).\")\n",
    "        Sigma = np.zeros((D, D))\n",
    "        \n",
    "    elif N < D + 1:\n",
    "        # N < D+1 の場合: 特異行列になるリスクが高いため、Ledoit-Wolf収縮推定を使用\n",
    "        warnings.warn(f\"N={N} < D+1={D+1}. Using Ledoit-Wolf shrinkage for robust covariance estimation.\")\n",
    "        \n",
    "        # Ledoit-Wolf収縮推定器を初期化・学習\n",
    "        lw = LedoitWolf()\n",
    "        lw.fit(X_data)\n",
    "        Sigma = lw.covariance_\n",
    "        \n",
    "    else:\n",
    "        # N >= D+1 の場合: 標準的な最尤推定を使用\n",
    "        Sigma = np.cov(X_data, rowvar=False)\n",
    "\n",
    "    # 3. 最終的な正則化チェック\n",
    "    # 収縮推定を行ってもなお条件数が悪い場合に、微小な値を加算\n",
    "    if np.linalg.cond(Sigma) > 1e15: # より厳しい条件数でチェック\n",
    "        warnings.warn(\"Covariance matrix highly ill-conditioned. Applying final small regularization.\")\n",
    "        Sigma += np.eye(D) * 1e-6\n",
    "        \n",
    "    return {'mu': mu, 'Sigma': Sigma}\n",
    "\n",
    "\n",
    "def kl_divergence_gaussian(mu1, Sigma1, mu2, Sigma2) -> float:\n",
    "    \"\"\"\n",
    "    多変量ガウス分布 N1 から N2 へのKL情報量 D_KL(N1 || N2) を計算する。\n",
    "    \"\"\"\n",
    "    D = mu1.shape[0]\n",
    "\n",
    "    try:\n",
    "        Sigma2_inv = inv(Sigma2)\n",
    "    except np.linalg.LinAlgError:\n",
    "        warnings.warn(\"Sigma2 is singular. KL divergence is undefined.\")\n",
    "        return np.nan\n",
    "\n",
    "    # 1. ログデターミナント項\n",
    "    log_det_term = np.log(det(Sigma2) / det(Sigma1))\n",
    "\n",
    "    # 2. トレース項\n",
    "    trace_term = np.trace(Sigma2_inv @ Sigma1)\n",
    "\n",
    "    # 3. マハラノビス距離項 (平均の違い)\n",
    "    diff_mu = mu2 - mu1\n",
    "    mahalanobis_term = diff_mu.T @ Sigma2_inv @ diff_mu\n",
    "\n",
    "    kl_div = 0.5 * (log_det_term + trace_term + mahalanobis_term - D)\n",
    "\n",
    "    return kl_div\n",
    "\n",
    "\n",
    "def bhattacharyya_coefficient_gaussian(mu1, Sigma1, mu2, Sigma2) -> float:\n",
    "    \"\"\"\n",
    "    多変量ガウス分布間のバタチャリヤ係数 BC を計算する。\n",
    "    値は0～1の範囲で、1に近いほど分布が重なっている。\n",
    "    \"\"\"\n",
    "    D = mu1.shape[0]\n",
    "    \n",
    "    # 共分散行列の平均 Sigma = 0.5 * (Sigma1 + Sigma2)\n",
    "    Sigma = 0.5 * (Sigma1 + Sigma2)\n",
    "\n",
    "    try:\n",
    "        Sigma_inv = inv(Sigma)\n",
    "    except np.linalg.LinAlgError:\n",
    "        warnings.warn(\"Sigma (mean covariance) is singular. Bhattacharyya Coefficient is undefined.\")\n",
    "        return np.nan\n",
    "\n",
    "    # 1. バタチャリヤ距離の平均項（マハラノビス距離の変形）\n",
    "    diff_mu = mu1 - mu2\n",
    "    db_mu_term = 0.125 * diff_mu.T @ Sigma_inv @ diff_mu\n",
    "\n",
    "    # 2. バタチャリヤ距離の共分散項\n",
    "    db_cov_term = 0.5 * np.log(det(Sigma) / np.sqrt(det(Sigma1) * det(Sigma2)))\n",
    "\n",
    "    # バタチャリヤ距離\n",
    "    db_distance = db_mu_term + db_cov_term\n",
    "    \n",
    "    # バタチャリヤ係数 = exp(-距離)\n",
    "    bc = np.exp(-db_distance)\n",
    "\n",
    "    return bc\n",
    "\n",
    "\n",
    "def mahalanobis_distance(mu1, mu2, Sigma_pooled) -> float:\n",
    "    \"\"\"\n",
    "    プールされた共分散行列 Sigma_pooled を用いて、2つの平均間のマハラノビス距離を計算する。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        Sigma_inv = inv(Sigma_pooled)\n",
    "    except np.linalg.LinAlgError:\n",
    "        warnings.warn(\"Sigma_pooled is singular. Mahalanobis distance is undefined.\")\n",
    "        return np.nan\n",
    "    \n",
    "    diff_mu = mu1 - mu2\n",
    "    # 距離の2乗\n",
    "    dist_sq = diff_mu.T @ Sigma_inv @ diff_mu\n",
    "    \n",
    "    return np.sqrt(dist_sq)\n",
    "\n",
    "\n",
    "print(\"統計量計算関数を定義しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02402bb",
   "metadata": {},
   "source": [
    "## 3. データと前処理の読み込み\n",
    "\n",
    "以下は例です。実際の処理に合わせて変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddcbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDBSCANクラスタリング結果の読み込み\n",
    "# clusterer: HDBSCANClustererインスタンス（condensed_treeとraw_treeを含む）\n",
    "# embedding: 高次元埋め込みデータ (N, D)\n",
    "# node_id_map: {sequential_idx: original_cluster_id}\n",
    "# id_point_map: {cluster_id: [point_indices]}\n",
    "\n",
    "# 例：\n",
    "# from hdbscan import HDBSCAN\n",
    "# clusterer = HDBSCAN(min_cluster_size=...)\n",
    "# clusterer.fit(X)\n",
    "# embedding = X  # または他の埋め込み\n",
    "# node_id_map = {...}\n",
    "# id_point_map = {...}\n",
    "\n",
    "print(\"データの読み込みが必要です（embeddings, node_id_map, id_point_map など）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063a2be4",
   "metadata": {},
   "source": [
    "## 4. クラスタ間の類似度計算（メイン処理）\n",
    "\n",
    "**動作説明：**\n",
    "\n",
    "1. **ループ構造**：すべてのクラスタペア (i, j) で i < j となるペアのみを処理（対称性を利用して計算量を半減）\n",
    "\n",
    "2. **クラスタ内のポイント取得**：\n",
    "   - `id_point_map[cluster_id]` → そのクラスタに属するポイントインデックスのリスト\n",
    "   - `embedding[point_indices]` → 当該ポイントの高次元ベクトル\n",
    "\n",
    "3. **ガウス分布パラメータ推定**：\n",
    "   - 各クラスタのポイント集合から、平均ベクトル (μ) と共分散行列 (Σ) を推定\n",
    "   - Ledoit-Wolf収縮法により、サンプル不足時の特異行列化を防止\n",
    "\n",
    "4. **類似度計算**：\n",
    "   - KLダイバージェンス：分布間の情報量の差（非対称）\n",
    "   - バタチャリヤ係数：分布の重なり度合い（対称、0～1）\n",
    "   - マハラノビス距離：分散を考慮したクラスタ中心間の距離\n",
    "\n",
    "5. **保存**：計算結果を辞書形式で pickle ファイルに保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb48bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスタ間の類似度を事前に計算する(辞書で保存)\n",
    "\n",
    "similarity_bc = {}\n",
    "similarity_kl = {}\n",
    "similarity_m = {}\n",
    "\n",
    "cluster_ids_list = list(node_id_map.keys())\n",
    "total_clusters = len(cluster_ids_list)\n",
    "\n",
    "for i, cluster_id1 in enumerate(cluster_ids_list):\n",
    "    if (i + 1) % max(1, total_clusters // 10) == 0:\n",
    "        print(f\"Processing cluster {i+1}/{total_clusters} (ID: {cluster_id1})\")\n",
    "    \n",
    "    # クラスタ1のポイントとデータを取得\n",
    "    point_ids1 = id_point_map[cluster_id1]\n",
    "    X_data1 = embedding[point_ids1]\n",
    "    params1 = estimate_single_gaussian_params(X_data1)\n",
    "    \n",
    "    for j, cluster_id2 in enumerate(cluster_ids_list):\n",
    "        if i >= j:\n",
    "            continue  # 対称性を利用して計算量削減\n",
    "        \n",
    "        # クラスタ2のポイントとデータを取得\n",
    "        point_ids2 = id_point_map[cluster_id2]\n",
    "        X_data2 = embedding[point_ids2]\n",
    "        params2 = estimate_single_gaussian_params(X_data2)\n",
    "        \n",
    "        # KLダイバージェンス\n",
    "        kl_div = kl_divergence_gaussian(params1['mu'], params1['Sigma'],\n",
    "                                        params2['mu'], params2['Sigma'])\n",
    "        \n",
    "        # バタチャリヤ係数\n",
    "        bc = bhattacharyya_coefficient_gaussian(params1['mu'], params1['Sigma'],\n",
    "                                                params2['mu'], params2['Sigma'])\n",
    "        \n",
    "        # マハラノビス距離\n",
    "        pooled_cov = 0.5 * (params1['Sigma'] + params2['Sigma'])\n",
    "        m_dist = mahalanobis_distance(params1['mu'], params2['mu'], pooled_cov)\n",
    "        \n",
    "        # 辞書に保存（cluster_id1, cluster_id2）をキーとして\n",
    "        similarity_kl[(cluster_id1, cluster_id2)] = kl_div\n",
    "        similarity_bc[(cluster_id1, cluster_id2)] = bc\n",
    "        similarity_m[(cluster_id1, cluster_id2)] = m_dist\n",
    "\n",
    "print(f\"\\n計算完了：{len(similarity_kl)} クラスタペア\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b55d5",
   "metadata": {},
   "source": [
    "## 5. 結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の統計情報を表示\n",
    "kl_values = list(similarity_kl.values())\n",
    "bc_values = list(similarity_bc.values())\n",
    "m_values = list(similarity_m.values())\n",
    "\n",
    "print(\"KL Divergence 統計:\")\n",
    "print(f\"  Min: {np.nanmin(kl_values):.4f}\")\n",
    "print(f\"  Max: {np.nanmax(kl_values):.4f}\")\n",
    "print(f\"  Mean: {np.nanmean(kl_values):.4f}\")\n",
    "print(f\"  NaN count: {np.sum(np.isnan(kl_values))}\")\n",
    "\n",
    "print(\"\\nBhattacharyya Coefficient 統計:\")\n",
    "print(f\"  Min: {np.nanmin(bc_values):.4f}\")\n",
    "print(f\"  Max: {np.nanmax(bc_values):.4f}\")\n",
    "print(f\"  Mean: {np.nanmean(bc_values):.4f}\")\n",
    "print(f\"  NaN count: {np.sum(np.isnan(bc_values))}\")\n",
    "\n",
    "print(\"\\nMahalanobis Distance 統計:\")\n",
    "print(f\"  Min: {np.nanmin(m_values):.4f}\")\n",
    "print(f\"  Max: {np.nanmax(m_values):.4f}\")\n",
    "print(f\"  Mean: {np.nanmean(m_values):.4f}\")\n",
    "print(f\"  NaN count: {np.sum(np.isnan(m_values))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0f9c9",
   "metadata": {},
   "source": [
    "## 6. 結果の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as file\n",
    "with open(\"cluster_similarities.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"kl_divergence\": similarity_kl,\n",
    "        \"bhattacharyya_coefficient\": similarity_bc,\n",
    "        \"mahalanobis_distance\": similarity_m\n",
    "    }, f)\n",
    "\n",
    "print(\"結果をファイルに保存しました: cluster_similarities.pkl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
